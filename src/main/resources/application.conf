spark {
  master = "yarn"
  driverMemory = "4g"
  executorMemory = "4g"
  numWorkers = 2
  targetPartitionSize = 10000
  minPartitions = 1
  maxPartitions = 100
}

model {
  outputDir = "hdfs:///model_output"
  metricsOutputDir = "hdfs:///metrics_output"
  windowSize = 128
  embeddingSize = 512
  hiddenSize = 1024
}

data {
  embeddingsPath = "hdfs:///embeddings/embeddings.txt"
}

training {
  batchSize = 32
  numEpochs = 10
  learningRate = 0.001
  trainSplit = 0.8
  validSplit = 0.2
}